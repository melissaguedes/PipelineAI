# Consulta Inteligente de Documentos

Este projeto apresenta um **pipeline completo**, projetado para capacitar modelos de linguagem a responderem perguntas com base em um conjunto de documentos heterog√™neos. A solu√ß√£o demonstra a capacidade de integrar diversas tecnologias de IA para extrair, indexar e recuperar informa√ß√µes de forma inteligente.

## Objetivo do Projeto

O objetivo principal deste desafio foi desenvolver uma solu√ß√£o funcional que:

* **Indexe documentos heterog√™neos:** Suporte para PDFs com texto nativo, PDFs digitalizados (imagens de documentos) e imagens (JPEG/PNG/WEBP contendo texto).
* **Aplique OCR (Optical Character Recognition) automaticamente:** Identifica a necessidade de OCR e o aplica de forma inteligente para extrair texto de conte√∫dos n√£o selecion√°veis.
* **Gere uma base vetorial:** Converte o texto extra√≠do em representa√ß√µes num√©ricas (embeddings) e as armazena de forma eficiente.
* **Implemente recupera√ß√£o de informa√ß√µes:** Busca os trechos mais relevantes do seu banco de dados vetorial em resposta a uma pergunta em linguagem natural.
* **Utilize uma Large Language Model (LLM) para responder perguntas:** Combina os trechos recuperados com uma LLM para gerar respostas contextualmente relevantes e precisas.

## Arquitetura do Pipeline

O pipeline √© modular e segue a abordagem RAG, dividindo o processo em tr√™s etapas principais para garantir efici√™ncia e escalabilidade:

1.  ### **Extra√ß√£o de Conte√∫do e Pr√©-processamento**
    Nesta fase, o sistema √© capaz de ler e processar diversos formatos de documentos:
    * **PDFs com texto nativo:** Utiliza `pdfplumber` para uma extra√ß√£o de texto precisa, mantendo a estrutura original (incluindo tabelas).
    * **PDFs digitalizados e Imagens (JPEG, PNG, WEBP):** Quando o texto n√£o √© nativamente selecion√°vel (em PDFs digitalizados) ou est√° em formato de imagem, o **OCR** √© acionado. `pytesseract` (interface para o **Tesseract OCR**) √© empregado para converter pixels em texto.
    * **Pr√©-processamento de Imagens:** Antes de alimentar as imagens ao Tesseract, `opencv-python-headless` √© utilizado para aplicar t√©cnicas de pr√©-processamento como convers√£o para escala de cinza, binariza√ß√£o (com o m√©todo de Otsu para ajuste autom√°tico de limiar) e redimensionamento. Essas etapas otimizam a qualidade da imagem para o OCR, **aumentando significativamente a acur√°cia da extra√ß√£o de texto**, especialmente em documentos com varia√ß√µes de qualidade.

2.  ### **Indexa√ß√£o Sem√¢ntica**
    Ap√≥s a extra√ß√£o do texto, as informa√ß√µes s√£o preparadas para uma recupera√ß√£o eficiente:
    * **Chunking:** O texto completo de todos os documentos √© dividido em **blocos (`chunks`) de 800 palavras**. Essa estrat√©gia garante que cada peda√ßo de informa√ß√£o seja grande o suficiente para conter contexto, mas pequeno o suficiente para ser processado pela LLM.
    * **Gera√ß√£o de Embeddings:** Cada chunk √© transformado em um **vetor sem√¢ntico (embedding)** usando o modelo `SentenceTransformer` (`all-MiniLM-L6-v2`). Esses vetores capturam o significado contextual do texto, permitindo compara√ß√µes sem√¢nticas.
    * **Armazenamento Vetorial:** Os embeddings s√£o armazenados e indexados em um banco de dados **FAISS (Facebook AI Similarity Search)**. O FAISS √© escolhido por sua alta performance em buscas de similaridade de vizinhos mais pr√≥ximos em espa√ßos de alta dimens√£o, essencial para a recupera√ß√£o r√°pida de informa√ß√µes relevantes.

3.  ### **Recupera√ß√£o e Gera√ß√£o com LLM**
    Esta √© a fase final, onde o sistema interage com o usu√°rio e gera respostas:
    * **Pergunta em Linguagem Natural:** O usu√°rio insere uma pergunta em linguagem natural.
    * **Busca de Similaridade:** A pergunta do usu√°rio √© convertida em um embedding (usando o mesmo `SentenceTransformer`) e utilizada para consultar o √≠ndice FAISS. Os **trechos (`chunks`) mais semanticamente relevantes** s√£o recuperados.
    * **Gera√ß√£o de Resposta pela LLM:** Os trechos recuperados, juntamente com a pergunta original, s√£o enviados ao modelo **`gemini-2.5-flash`** da Google via `google-generativeai` API. A LLM utiliza esse contexto fornecido para gerar uma resposta concisa, relevante e baseada nas informa√ß√µes contidas nos documentos. O prompt √© constru√≠do para instruir a LLM a **responder estritamente com base no contexto fornecido**, minimizando alucina√ß√µes.

## Tecnologias Utilizadas

* **`Python`**: A linguagem de escolha pela sua maturidade e ecossistema robusto para IA, oferecendo bibliotecas de ponta para PNL, vis√£o computacional e aprendizado de m√°quina. Sua sintaxe limpa e legibilidade aceleram a prototipa√ß√£o e o desenvolvimento.

* **`pdfplumber`**: Uma biblioteca Python para extra√ß√£o de texto de PDFs. Foi selecionada por sua capacidade de lidar com PDFs com texto nativo de forma eficaz, extraindo n√£o apenas o texto, mas tamb√©m informa√ß√µes de layout como tabelas e coordenadas, que poderiam ser √∫teis em desenvolvimentos futuros.

* **`pytesseract` (com Tesseract OCR)**: Um wrapper Python para o popular motor OCR de c√≥digo aberto Tesseract. Escolhido pela sua robustez e flexibilidade, incluindo suporte nativo a m√∫ltiplos idiomas (configurado para `portugu√™s`) e a capacidade de ser acionado condicionalmente para PDFs digitalizados e imagens.

* **`opencv-python-headless`**: A biblioteca OpenCV √© muito utilizada para o pr√©-processamento de imagens. A vers√£o `headless` √© ideal para ambientes de servidor/Colab, pois n√£o requer interface gr√°fica. As opera√ß√µes de binariza√ß√£o (Otsu) e redimensionamento s√£o cruciais para otimizar a entrada para o Tesseract, melhorando a acur√°cia do OCR em imagens variadas.

* **`sentence-transformers`**: Uma biblioteca para gerar embeddings de senten√ßas, par√°grafos e documentos. O modelo `all-MiniLM-L6-v2` foi escolhido por seu equil√≠brio entre desempenho, velocidade e tamanho compacto, tornando-o eficiente para gerar embeddings de alta qualidade sem exigir grandes recursos computacionais.

* **`faiss-cpu`**: Desenvolvido pelo Facebook AI, o FAISS √© uma biblioteca para pesquisa eficiente de similaridade e agrupamento de vetores de alta dimens√£o. A vers√£o `faiss-cpu` foi escolhida para execu√ß√£o local (ou em ambientes como Colab), fornecendo um desempenho de busca de vizinhos mais pr√≥ximos extremamente r√°pido e escal√°vel para milh√µes de vetores.

* **`google-generativeai` (Gemini API)**: A interface Python para os modelos Gemini da Google. O `gemini-2.5-flash` √© um modelo de linguagem grande otimizado para tarefas de resposta r√°pida e efici√™ncia, ideal para ser a LLM no pipeline RAG, processando o contexto recuperado e gerando respostas coerentes e informativas.


## Guia de Execu√ß√£o (via Google Colab)

Siga os passos abaixo para configurar e executar o pipeline no Google Colab:

1.  ### **Acesse o Notebook:**
    Clique no link para abrir o notebook no Google Colab:
    [üìé Desafio.ipynb](https://colab.research.google.com/drive/1BPBTaotNlB6AL570uBKyZ9p_xvhemw2A?usp=sharing)

2.  ### **Fa√ßa Upload dos Documentos:**
    Execute a c√©lula que utiliza `from google.colab import files; uploaded = files.upload()`. Uma caixa de di√°logo aparecer√°, permitindo que voc√™ selecione os arquivos do seu computador. Fa√ßa upload dos documentos fornecidos para o desafio:
    * `C√ìDIGO DE OBRAS.pdf`
    * `tabela.webp`

3.  ### **Execute as Etapas do Pipeline (C√©lula por C√©lula):**
    Prossiga executando as c√©lulas do notebook sequencialmente:
    * **Etapa 1: Extra√ß√£o de Texto com OCR Condicional:** Esta c√©lula processar√° os documentos enviados, extraindo texto nativo ou aplicando OCR conforme necess√°rio. O texto consolidado ser√° salvo em `extracted_text.txt`.
    * **Etapa 2: Chunking, Embeddings e Indexa√ß√£o:** Esta c√©lula ler√° o `extracted_text.txt`, dividir√° o conte√∫do em chunks, gerar√° embeddings para cada chunk e os indexar√° no FAISS.
    * **Etapa 3: Perguntas e Respostas via Gemini:** Esta √© a etapa interativa. Ap√≥s a execu√ß√£o, voc√™ ser√° solicitado a digitar suas perguntas no console. O sistema recuperar√° o contexto relevante e usar√° o Gemini para gerar respostas. Digite 'sair' para encerrar a sess√£o.


## Autor
Desenvolvido por Melissa Guedes.
